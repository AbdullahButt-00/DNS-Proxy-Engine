# flask_app.py

# â”€â”€ 0) Autoâ€“download (or load) the ML model if itâ€™s not cached â”€â”€â”€â”€â”€â”€â”€
print("ğŸ”½ Checking ML model cacheâ€¦")
try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    MODEL = "kmack/malicious-url-detection"

    # This will download if missing, or load from ~/.cache/huggingface otherwise
    AutoTokenizer.from_pretrained(MODEL)
    AutoModelForSequenceClassification.from_pretrained(MODEL)
    print("âœ… ML model is cached and ready.")
except Exception as e:
    print(f"âŒ Failed to cache ML model: {e}")
    # You can choose to exit here if caching is absolutely required:
    # import sys; sys.exit(1)

# â”€â”€ 1) Now import everything else â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import threading
import time
import logging
from collections import deque

from flask import Flask, render_template, jsonify, request
from dnslib.server import DNSServer

import simple_proxy as sp    # your DNS + scoring logic (uses ml_api internally)
import ml_api                 # the FastAPI ML scoring service
print(">> ml_api loaded from", ml_api.__file__)
print(">> ml_api has attributes", dir(ml_api))

import uvicorn                # programmatic Uvicorn runner

# â”€â”€ 2) Flask app & in-memory logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)

log_buffer = deque(maxlen=500)
class InMemoryHandler(logging.Handler):
    def emit(self, record):
        log_buffer.append(self.format(record))

proxy_logger = logging.getLogger("simple_proxy")
proxy_logger.setLevel(logging.INFO)
mem_handler = InMemoryHandler()
mem_handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
proxy_logger.addHandler(mem_handler)

# â”€â”€ 3) ML API background thread â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_ml_api():
    uvicorn.run(
        app=ml_api.app,
        host="127.0.0.1",
        port=8500,
        log_level="info",
        access_log=False,
    )

threading.Thread(target=run_ml_api, daemon=True).start()
proxy_logger.info("ğŸ›°ï¸ ML API server starting on http://127.0.0.1:8500")

# â”€â”€ 4) DNS proxy background thread â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_dns_proxy():
    resolver = sp.SimpleResolver()
    server   = DNSServer(
        resolver,
        address=sp.LISTEN_ADDR,
        port=sp.LISTEN_PORT,
        tcp=False,
        logger=None  # use dnslib's default logger
    )
    server.start_thread()
    proxy_logger.info(f"âœ… DNS Proxy listening on {sp.LISTEN_ADDR}:{sp.LISTEN_PORT}")

threading.Thread(target=run_dns_proxy, daemon=True).start()

# â”€â”€ 5) Flask routes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/")
def index():
    return render_template("index.html")

@app.route("/logs")
def logs():
    return jsonify(list(log_buffer)[-500:])

@app.route("/status")
def status():
    return jsonify({
        "running"             : True,
        "mode"                : "MONITOR" if sp.MONITOR_MODE else "ACTIVE",
        "block_threshold"     : sp.BLOCK_THR,
        "suspicious_threshold": sp.SUSP_THR
    })

@app.route("/toggle_mode", methods=["POST"])
def toggle_mode():
    sp.MONITOR_MODE = not sp.MONITOR_MODE
    mode = "MONITOR" if sp.MONITOR_MODE else "ACTIVE"
    proxy_logger.warning(f"### Mode switched to {mode} ###")
    return jsonify({"mode": mode})

# â”€â”€ 6) Entrypoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # Launch Flask (this also keeps the main thread alive)
    app.run(host="0.0.0.0", port=8000, debug=True)
